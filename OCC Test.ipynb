{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "002dafc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join\n",
    "from PIL import ImageFile\n",
    "import pandas as pd\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn import svm\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "import re\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5d5604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_dir_n = \"C:\\\\Github\\\\Image-Processing-Project\\\\Dataset\\\\natural_images\\\\flower\"\n",
    "train_img_paths_n = [join(train_img_dir_n,filename) for filename in os.listdir(train_img_dir_n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73a95538",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_paths, test_img_paths_flower = train_test_split(train_img_paths_n, test_size=0.25, random_state=42)\n",
    "train_img_paths, val_img_paths_flower = train_test_split(train_img_paths, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39a4c259",
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_images_path = \"C:\\\\Github\\\\Image-Processing-Project\\\\Dataset\\\\natural_images\\\\\"\n",
    "test_img_paths_no_flower = []\n",
    "for d in [d for d in os.listdir(\"C:\\\\Github\\\\Image-Processing-Project\\\\Dataset\\\\natural_images\") if d!= \"flower\"]:\n",
    "    test_img_dir_na = natural_images_path+d\n",
    "    test_img_paths_no_flower.append([join(test_img_dir_na,filename) for filename in os.listdir(test_img_dir_na)])\n",
    "    \n",
    "test_img_paths_no_flower_flat = [item for sublist in test_img_paths_no_flower for item in sublist]\n",
    "test_img_paths_no_flower, val_img_paths_no_flower = train_test_split(test_img_paths_no_flower_flat, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "220a1cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def natural_img_dir(image_path):\n",
    "    path_regex = r'natural_images\\\\(W*)'\n",
    "    if 'natural_images' in image_path:\n",
    "        return re.findall(path_regex,image_path,re.MULTILINE)[0].strip()\n",
    "    else:\n",
    "        return 'flower'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d36721e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_paths = test_img_paths_flower+test_img_paths_no_flower\n",
    "test_path_df = pd.DataFrame({'path': all_test_paths,'is_flower': [1 if path in test_img_paths_flower else 0 \n",
    "                                                                  for path in all_test_paths]})\n",
    "test_path_df = shuffle(test_path_df,random_state = 0).reset_index(drop = True)\n",
    "test_path_df['image_type'] = test_path_df['path'].apply(lambda x: natural_img_dir(x))\n",
    "all_test_paths = test_path_df['path'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f191ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_val_paths = val_img_paths_flower+val_img_paths_no_flower\n",
    "val_path_df = pd.DataFrame({\n",
    "    'path': all_val_paths,\n",
    "    'is_flower': [1 if path in val_img_paths_flower else 0 for path in all_val_paths]\n",
    "})\n",
    "val_path_df = shuffle(val_path_df,random_state = 0).reset_index(drop = True)\n",
    "val_path_df['image_type'] = val_path_df['path'].apply(lambda x: natural_img_dir(x))\n",
    "all_val_paths = val_path_df['path'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db03d9f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "\n",
    "def read_and_prep_images(img_paths, img_height=image_size, img_width=image_size):\n",
    "    imgs = [load_img(img_path, target_size=(img_height, img_width)) for img_path in img_paths]\n",
    "    img_array = np.array([img_to_array(img) for img in imgs])\n",
    "    #output = img_array\n",
    "    output = preprocess_input(img_array)\n",
    "    return(output)\n",
    "\n",
    "X_train = read_and_prep_images(train_img_paths)\n",
    "X_test = read_and_prep_images(all_test_paths)\n",
    "X_val = read_and_prep_images(all_val_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5731a16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(474, 224, 224, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8912db15",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot assign value to variable ' conv3_block1_0_conv/kernel:0': Shape mismatch.The variable shape (1, 1, 256, 512), and the assigned value shape (512, 128, 1, 1) are incompatible.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [47], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m resnet_weights_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC://Github//Image-Processing-Project//ResNet50_weight//resnet50_weights_tf_dim_ordering_tf_kernels.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# X : images numpy array\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m resnet_model \u001b[38;5;241m=\u001b[39m \u001b[43mResNet50\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresnet_weights_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mavg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Since top layer is the fc layer used for predictions\u001b[39;00m\n\u001b[0;32m      6\u001b[0m X_train \u001b[38;5;241m=\u001b[39m resnet_model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[0;32m      7\u001b[0m X_test \u001b[38;5;241m=\u001b[39m resnet_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AI4H\\lib\\site-packages\\keras\\applications\\resnet.py:521\u001b[0m, in \u001b[0;36mResNet50\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[0;32m    518\u001b[0m     x \u001b[38;5;241m=\u001b[39m stack1(x, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m6\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stack1(x, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m3\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ResNet(\n\u001b[0;32m    522\u001b[0m     stack_fn,\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    524\u001b[0m     \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnet50\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    526\u001b[0m     include_top,\n\u001b[0;32m    527\u001b[0m     weights,\n\u001b[0;32m    528\u001b[0m     input_tensor,\n\u001b[0;32m    529\u001b[0m     input_shape,\n\u001b[0;32m    530\u001b[0m     pooling,\n\u001b[0;32m    531\u001b[0m     classes,\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    533\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AI4H\\lib\\site-packages\\keras\\applications\\resnet.py:240\u001b[0m, in \u001b[0;36mResNet\u001b[1;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_weights(weights_path)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 240\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AI4H\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AI4H\\lib\\site-packages\\keras\\backend.py:4302\u001b[0m, in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   4300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m tf\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m   4301\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, value \u001b[38;5;129;01min\u001b[39;00m tuples:\n\u001b[1;32m-> 4302\u001b[0m         \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4303\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4304\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_graph()\u001b[38;5;241m.\u001b[39mas_default():\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot assign value to variable ' conv3_block1_0_conv/kernel:0': Shape mismatch.The variable shape (1, 1, 256, 512), and the assigned value shape (512, 128, 1, 1) are incompatible."
     ]
    }
   ],
   "source": [
    "resnet_weights_path = 'C://Github//Image-Processing-Project//ResNet50_weight//resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "# X : images numpy array\n",
    "resnet_model = ResNet50(input_shape=(image_size, image_size, 3), weights=resnet_weights_path, include_top=False, pooling='avg')  # Since top layer is the fc layer used for predictions\n",
    "\n",
    "X_train = resnet_model.predict(X_train)\n",
    "X_test = resnet_model.predict(X_test)\n",
    "X_val = resnet_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b49e058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
